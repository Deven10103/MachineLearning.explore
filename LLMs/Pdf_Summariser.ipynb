{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1rx1TGi5F9blkEcySPVbr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deven10103/MachineLearning.explore/blob/main/LLMs/Pdf_Summariser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M05PG9TX97k0",
        "outputId": "ef39a624-cf0f-42be-96f6-754462c77810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/304.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ\u001b[0m \u001b[32m297.0/304.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m304.6/304.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/69.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/438.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m438.9/438.9 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/45.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio openai pypdf tiktoken langchain langchain_community langchain-openai\n",
        "# Installing the packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(dotenv_path=\"/content/keys.env\")\n",
        "\n",
        "openai = os.getenv(\"OPENAI_API_KEY\")\n",
        "print(openai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsc1cF6FC143",
        "outputId": "b264231c-9b7e-4881-89a5-a072ce63a990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def tokenize(string: str,encodingnm: str) -> int:\n",
        "  encoding = tiktoken.get_encoding(encodingnm)\n",
        "  num_tokens=len(encoding.encode(string))\n",
        "  print(encoding.encode(string))\n",
        "  return num_tokens\n",
        "\n",
        "tokenize(\"tiktoken is being used.\",\"cl100k_base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TSjsABHIbHi",
        "outputId": "d1c1b687-2dc9-4b40-d06f-c256b05c9210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[83, 1609, 5963, 374, 1694, 1511, 13]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio\n",
        "from langchain import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "llm=ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "UIwSo_RBMMf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(file_path):\n",
        "  loader=PyPDFLoader(file_path)\n",
        "  docs =loader.load_and_split()\n",
        "  chain = load_summarize_chain(llm=llm, chain_type=\"map_reduce\")\n",
        "  summary=chain.run(docs)\n",
        "\n",
        "  return summary"
      ],
      "metadata": {
        "id": "JNk0h9iQP8sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(\"/content/HorchreiterSchmidhuber_LSTM.pdf\")\n"
      ],
      "metadata": {
        "id": "ZrKP2bmuRat4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentencepiece torch nltk pypdf\n",
        "\n",
        "#  pymupdf"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4FI9o9sRmcxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "from pypdf import PdfReader\n",
        "\n",
        "def extract_text_from_pdf(filepath):\n",
        "    reader = PdfReader(filepath)\n",
        "    # print(reader)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() or \"\"\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "id": "8M00-onxovir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we are not using BERT or LangChain we dont need limiting our tokens for a\n",
        "# particular model\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def split_text(text, max_tokens=512):\n",
        "    v=0\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks, chunk = [], ''\n",
        "    for sentence in sentences:\n",
        "        if len(chunk.split()) + len(sentence.split()) <= max_tokens:\n",
        "            chunk += sentence + ' '\n",
        "        else:\n",
        "            # print(len(word_tokenize(chunk)))\n",
        "            chunks.append(chunk.strip())\n",
        "            chunk = sentence + ' '\n",
        "    if chunk:\n",
        "        chunks.append(chunk.strip())\n",
        "    print(\"Chunking Completed!!\")\n",
        "    return chunks\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1wwlAeqrAMe",
        "outputId": "a2207221-af53-4217-8022-29991ce75007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should return True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQF_q88k9Fxh",
        "outputId": "69b4d8c1-1ae2-46c4-8a44-09428d5abf8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# summarizer = pipeline(\"summarization\", model=\"bigbird-pegasus\")\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"google/bigbird-pegasus-large-arxiv\",\n",
        "    tokenizer=\"google/bigbird-pegasus-large-arxiv\",\n",
        "    device=0  # use -1 for CPU, or 0 if running on GPU\n",
        ")\n",
        "# !pip install transformers\n",
        "# !pip install transformers[sentencepiece]\n",
        "\n",
        "# from transformers import AutoTokenizer, AutoModelForConditionalGeneration\n",
        "\n",
        "# # Load model/tokenizer\n",
        "# model_name = \"google/bigbird-pegasus-large-arxiv\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForConditionalGeneration.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "wxOUpV6GtpW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarizeMapReduce(chunks):\n",
        "    # chunks = split_text(text)\n",
        "    print(\"Starting Summarization!\")\n",
        "    summaries = []\n",
        "\n",
        "    for chunk in chunks:\n",
        "        summary = summarizer(chunk, batch_size=16, max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
        "        summaries.append(summary)\n",
        "    # final_summary = summarizer(\" \".join(summaries), batch_size=16, max_length=150, min_length=50, do_sample=False)[0]['summary_text']\n",
        "    print(\"Finished Summarization!\")\n",
        "    return \" \".join(summaries)\n"
      ],
      "metadata": {
        "id": "GQLGBb5bvlZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarizeRefine(chunks):\n",
        "    # chunks = split_text(text)\n",
        "    print(\"Starting Summarization!\")\n",
        "    summary_so_far = summarizer(chunks[0], max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
        "\n",
        "    for i in range(1, len(chunks)):\n",
        "        prompt = f\"Current summary: {summary_so_far}\\n\\nNew content: {chunks[i]}\\n\\nImprove the summary based on the new content.\"\n",
        "        summary_so_far = summarizer(prompt, max_length=120, min_length=50, do_sample=False)[0]['summary_text']\n",
        "    print(\"Finished Summarization!\")\n",
        "    return summary_so_far\n"
      ],
      "metadata": {
        "id": "vlosuuRawLPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "filepath = \"/content/Introduction_to_Quantum_Key_Distribution.pdf\"\n",
        "\n",
        "text = extract_text_from_pdf(filepath)\n",
        "\n",
        "# inputs = tokenizer(\n",
        "#     text,\n",
        "#     return_tensors=\"pt\",\n",
        "#     max_length=4096,\n",
        "#     truncation=True\n",
        "# )\n",
        "\n",
        "# summary_ids = model.generate(\n",
        "#     input_ids=inputs['input_ids'],\n",
        "#     attention_mask=inputs['attention_mask'],\n",
        "#     max_length=512,\n",
        "#     min_length=100,\n",
        "#     num_beams=4,\n",
        "#     early_stopping=True\n",
        "# )\n",
        "\n",
        "# summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "# print(\"üìÑ Summary:\\n\", summary)\n",
        "# sample_text = \"What is Computer Vision? Computer vision can be defined as that branch of computer science dealing with the computer's understanding of digital images, videos, and other forms of visual input. It enables machines to see and comprehend the world around them similarly to human beings. In layman's terms, computer vision lets machines recognize objects, trace their movements, and interpret scenes. They are ultimately able to decide based on what their eyesight tells them. It includes different processes such as image processing, pattern recognition, and machine learning. Algorithms analyze visual data, detecting patterns and making predictions. The aim of the technique is to allow machines to automatically interpret and make decisions based on visual data.Applications of Computer Vision Computer vision has applications in all industries and sectors and they are as follows: 1. Oil and natural gas The oil and natural gas companies produce millions of barrels of oil and billions of cubic feet of gas every day but for this to happen, first, the geologists have to find a feasible location from where oil and gas can be extracted. To find these locations they have to analyze thousands of different locations using images taken on the spot. Suppose if geologists had to analyze each image manually how long would it take to find the best location? Maybe months or even a year but due to the introduction of computer vision the period of analyzing can be brought down to a few days or even a few hours. You just need to feed in the images taken to the pre-trained model and it will get the work done. 2. Hiring process In the HR world, computer vision is changing how candidates get hired in the interview process. By using computer vision, machine learning, and data science, they're able to quantify soft skills and conduct early candidate assessments to help large companies shortlist the candidates. 3. Video surveillance The Concept of video tagging is used to tag videos with keywords based on the objects that appear in each scene. Now imagine being that security company who's asking to look for a suspect in a blue van amongst hours and hours of footage. You will just have to feed the video to the algorithm. With computer vision and object recognition, searching through videos has become a thing of the past.\"\n",
        "chunks = split_text(text)\n",
        "# final_summary = summarizeRefine(text)\n",
        "prefinal_summary = summarizeMapReduce(chunks)\n",
        "\n",
        "new_chunks=split_text(prefinal_summary,1024)\n",
        "final_summary=summarizeMapReduce(new_chunks)\n",
        "\n",
        "\n",
        "print(\"Final Refined Summary:\\n\", final_summary.replace(\"<n>\",\"\\n\"))\n",
        "# print(\"Final Refined Summary:\\n\", final_summary)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E_hPWa6xlXb",
        "outputId": "9c7a5b26-b397-456a-e2f4-f4cf993d17ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunking Completed!!\n",
            "Starting Summarization!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attention type 'block_sparse' is not possible if sequence_length: 702 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Summarization!\n",
            "Chunking Completed!!\n",
            "Starting Summarization!\n",
            "Finished Summarization!\n",
            "Final Refined Summary:\n",
            " quantum cryptography is an emerging technology that promises to solve several problems of conventional cryptography , including , but not limited to , key distribution , cloning , and secret key generation .\n",
            " quantum cryptography can be performed using a quantum computer with an advantage over ir classical counterparts .\n",
            " quantum cryptography is a cryptographic primitive used for secure direct communication between remote parties .\n",
            " the security of public authentication and quantum key distribution ( qkd ) is secure in this paper , in this paper we present a protocol for the secure transmission of quantum information which does not require any kind of measurement or leakage of quantum states quantum key distribution ( qkd ) protocol in which alice s key is shared between bob and jimenez .\n",
            " the security of qkd is based on the principle of non - contextuality , which states that an attacker does not trust any eavesdropper .\n",
            " the security of qkd is based on the principle of we consider the interaction of a wave with a point on the surface of a sphere .\n",
            " we show that a wave traveling along a straight line at constant speed , _\n",
            " i.e. _ , on the surface of a sphere , will not be reflected by a point on the surface of a sphere .\n",
            " we also show that a wave traveling along a straight line at constant speed , _\n",
            " i.e. _ , on the surface\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(final_summary))\n",
        "print(len(final_summary.replace(\"<n>\",\"\\n\")))\n",
        "print(final_summary.count(\"<n>\"))\n",
        "\n",
        "print(len(chunks))"
      ],
      "metadata": {
        "id": "57gj3fwjSz7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using PyMuPDF for layout based chinking."
      ],
      "metadata": {
        "id": "pAeGc2aa2EUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n",
        "!pip install transformers\n",
        "\n",
        "import fitz\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "MAX_TOKENS = 1000"
      ],
      "metadata": {
        "collapsed": true,
        "id": "H9ExhHya2DCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_blocks(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    blocks = []\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc[page_num]\n",
        "        for b in page.get_text(\"blocks\"):\n",
        "\n",
        "            x0, y0, x1, y1, text, block_no, block_type = b\n",
        "            if text.strip():\n",
        "                blocks.append({\n",
        "                    \"page\": page_num,\n",
        "                    \"bbox\": (x0, y0, x1, y1),\n",
        "                    \"text\": text.strip()\n",
        "                })\n",
        "    return blocks\n",
        "\n",
        "def sort_blocks(blocks):\n",
        "    return sorted(blocks, key=lambda b: (b[\"page\"], b[\"bbox\"][1]))"
      ],
      "metadata": {
        "id": "4vO5Ombd2d45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_tokenize(text):\n",
        "    return text.split()"
      ],
      "metadata": {
        "id": "XOyQN6Su2ja7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_tokenize(text):\n",
        "    return tokenizer.encode(text, add_special_tokens=False)"
      ],
      "metadata": {
        "id": "lPuZe3kJ2j3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_chunks(blocks, max_tokens=MAX_TOKENS):\n",
        "    chunks = []\n",
        "    current_chunk_tokens = []\n",
        "\n",
        "    for block in blocks:\n",
        "        block_tokens = simple_tokenize(block[\"text\"])\n",
        "\n",
        "        # If adding this block exceeds max_tokens, flush current chunk\n",
        "        if len(current_chunk_tokens) + len(block_tokens) > max_tokens:\n",
        "            if current_chunk_tokens:\n",
        "                chunks.append(\" \".join(current_chunk_tokens))\n",
        "            current_chunk_tokens = block_tokens\n",
        "        else:\n",
        "            current_chunk_tokens.extend(block_tokens)\n",
        "\n",
        "        # If the block itself was huge, split inside it\n",
        "        while len(current_chunk_tokens) > max_tokens:\n",
        "            chunks.append(\" \".join(current_chunk_tokens[:max_tokens]))\n",
        "            current_chunk_tokens = current_chunk_tokens[max_tokens:]\n",
        "\n",
        "    if current_chunk_tokens:\n",
        "        chunks.append(\" \".join(current_chunk_tokens))\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "S5W-HqZV2UXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file = \"/content/Introduction_to_Quantum_Key_Distribution.pdf\"\n",
        "\n",
        "blocks = extract_blocks(pdf_file)\n",
        "sorted_blocks = sort_blocks(blocks)\n",
        "PMPchunks = create_chunks(sorted_blocks, MAX_TOKENS)\n",
        "\n",
        "# print(len())\n",
        "for i, chunk in enumerate(PMPchunks):\n",
        "    print(f\"\\n--- Chunk {i+1} ({len(chunk.split())} tokens) ---\\n{chunk[:100]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzyRdT1N2Uu_",
        "outputId": "4c91003e-4459-4399-a2e8-db9563638eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Chunk 1 (818 tokens) ---\n",
            "Introduction to Quantum Key Distribution Vicente Martin‚àó1, Jesus Martinez-Mateo‚Ä†1, and Momtchil Peev...\n",
            "\n",
            "--- Chunk 2 (876 tokens) ---\n",
            "ing block (subroutine) needed to transmit secrets with absolute security, serving as an input to the...\n",
            "\n",
            "--- Chunk 3 (993 tokens) ---\n",
            "Inspired by the early 1970‚Äôs ideas of Stephen J. Wiesner about quantum money, later published in 198...\n",
            "\n",
            "--- Chunk 4 (751 tokens) ---\n",
            "Figure 1: The process of growing a key between the two end points of a quantum channel, here labeled...\n",
            "\n",
            "--- Chunk 5 (653 tokens) ---\n",
            "The unconditional security of the protocols based on these intuitive ideas has been Ô¨Årst formally pr...\n",
            "\n",
            "--- Chunk 6 (895 tokens) ---\n",
            "The most signiÔ¨Åcant limit for QKD in the foreseeable future is imposed by the at- tenuation in the p...\n",
            "\n",
            "--- Chunk 7 (1000 tokens) ---\n",
            "weak coherent pulses. A laser pulse is attenuated to a level such that it carries only one (or less)...\n",
            "\n",
            "--- Chunk 8 (1000 tokens) ---\n",
            "4.4 Other protocols While the BB84 protocol has historically been the Ô¨Årst one, diÔ¨Äerent classes of ...\n",
            "\n",
            "--- Chunk 9 (867 tokens) ---\n",
            "The point to point character and the requirements of single quantum transmission makes QKD a diÔ¨Écult...\n",
            "\n",
            "--- Chunk 10 (754 tokens) ---\n",
            "To reduce the cost, the ability to use the same Ô¨Åber for classical communications and the quantum ch...\n",
            "\n",
            "--- Chunk 11 (732 tokens) ---\n",
            "As described above, information reconciliation basically consists in exchanging messages over a publ...\n",
            "\n",
            "--- Chunk 12 (976 tokens) ---\n",
            "A number of proposals aim to reduce the interactivity of Cascade using one-way (for- ward) error cor...\n",
            "\n",
            "--- Chunk 13 (1000 tokens) ---\n",
            "After the physical part of a QKD protocol and the basis and information reconciliation steps, the pa...\n",
            "\n",
            "--- Chunk 14 (987 tokens) ---\n",
            "[24] M. Peev, C. Pacher, R. All¬¥eaume, C. Barreiro, J. Bouda, W. Boxleitner, T. De- buisschert, E. D...\n",
            "\n",
            "--- Chunk 15 (503 tokens) ---\n",
            "[56] P. Eraerds, N. Walenta, M. Legr¬¥e, N. Gisin, and H. Zbinden, New J. Phys., vol. 12, no. 6, p. 0...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarizer :\n",
        " https://colab.research.google.com/drive/1ER0JANbdobS3RzhaHSPCvdBQ4O5GL_yN#scrollTo=wxOUpV6GtpW-&line=1&uniqifier=1"
      ],
      "metadata": {
        "id": "_boe2cPwCQDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_summary=summarizeMapReduce(PMPchunks)\n",
        "print(\"Final Refined Summary:\\n\", final_summary.replace(\"<n>\",\"\\n\"))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "n5WpckDwA1Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ERM0hhWEE3d5"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}